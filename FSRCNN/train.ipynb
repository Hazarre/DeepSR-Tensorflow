{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from model import FSRCNN\n",
    "\n",
    "# Allow local import from parent directory\n",
    "# sys.path.insert(0, \"..\")\n",
    "# from dataset import deserialize\n",
    "# from common import normalize_y\n",
    "\n",
    "\n",
    "# def preprocess(example): \n",
    "#     lr, hr = deserialize(example)\n",
    "#     hr = normalize_y(hr)    \n",
    "#     lr = normalize_y(lr)\n",
    "#     return lr, hr\n",
    "\n",
    "SIZE = 100\n",
    "CHN  = 1\n",
    "R = 4\n",
    "\n",
    "\n",
    "def normalize_y(y_array, scale=219, offset=16):\n",
    "    # for y-channel to [0, 1]\n",
    "    y_array = tf.cast(y_array, dtype=\"float32\")\n",
    "    return (y_array - offset) / scale\n",
    "\n",
    "\n",
    "def preprocess(example):\n",
    "    image_feature_description = {\"lr\": tf.io.FixedLenFeature([], tf.string),\n",
    "                                 \"hr\": tf.io.FixedLenFeature([], tf.string)}\n",
    "      \n",
    "    example = tf.io.parse_single_example(example, image_feature_description)\n",
    "    lr = tf.io.decode_raw(example[\"lr\"], out_type=\"uint8\")\n",
    "    hr = tf.io.decode_raw(example[\"hr\"], out_type=\"uint8\")\n",
    "    shape = [SIZE, SIZE, CHN]\n",
    "    hr = tf.reshape(hr, shape=shape)\n",
    "    shape = [SIZE//R, SIZE//R, CHN]\n",
    "    lr = tf.reshape(lr, shape=shape)\n",
    "    hr = normalize_y(hr)    \n",
    "    lr = normalize_y(lr)\n",
    "    return lr, hr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/300\n",
      "      1/Unknown - 0s 999us/step - loss: 6.5463e-04WARNING:tensorflow:From C:\\Users\\henrychang\\miniconda3\\envs\\deepsr\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  13131/Unknown - 605s 46ms/step - loss: 0.0018\n",
      "Epoch 00149: saving model to checkpoints\\FSRCNN149.ckpt\n",
      "13132/13132 [==============================] - 630s 48ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 150/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00150: saving model to checkpoints\\FSRCNN150.ckpt\n",
      "13132/13132 [==============================] - 642s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 151/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00151: saving model to checkpoints\\FSRCNN151.ckpt\n",
      "13132/13132 [==============================] - 630s 48ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 152/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00152: saving model to checkpoints\\FSRCNN152.ckpt\n",
      "13132/13132 [==============================] - 633s 48ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 153/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00153: saving model to checkpoints\\FSRCNN153.ckpt\n",
      "13132/13132 [==============================] - 628s 48ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 154/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00154: saving model to checkpoints\\FSRCNN154.ckpt\n",
      "13132/13132 [==============================] - 630s 48ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 155/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00155: saving model to checkpoints\\FSRCNN155.ckpt\n",
      "13132/13132 [==============================] - 631s 48ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 156/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00156: saving model to checkpoints\\FSRCNN156.ckpt\n",
      "13132/13132 [==============================] - 640s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 157/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00157: saving model to checkpoints\\FSRCNN157.ckpt\n",
      "13132/13132 [==============================] - 640s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 158/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00158: saving model to checkpoints\\FSRCNN158.ckpt\n",
      "13132/13132 [==============================] - 642s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 159/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00159: saving model to checkpoints\\FSRCNN159.ckpt\n",
      "13132/13132 [==============================] - 652s 50ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 160/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00160: saving model to checkpoints\\FSRCNN160.ckpt\n",
      "13132/13132 [==============================] - 637s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 161/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00161: saving model to checkpoints\\FSRCNN161.ckpt\n",
      "13132/13132 [==============================] - 640s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 162/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00162: saving model to checkpoints\\FSRCNN162.ckpt\n",
      "13132/13132 [==============================] - 639s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 163/300\n",
      "13132/13132 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00163: saving model to checkpoints\\FSRCNN163.ckpt\n",
      "13132/13132 [==============================] - 640s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 164/300\n",
      "13132/13132 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00164: saving model to checkpoints\\FSRCNN164.ckpt\n",
      "13132/13132 [==============================] - 641s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 165/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00165: saving model to checkpoints\\FSRCNN165.ckpt\n",
      "13132/13132 [==============================] - 643s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 166/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00166: saving model to checkpoints\\FSRCNN166.ckpt\n",
      "13132/13132 [==============================] - 606s 46ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 167/300\n",
      "13132/13132 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00167: saving model to checkpoints\\FSRCNN167.ckpt\n",
      "13132/13132 [==============================] - 578s 44ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 168/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00168: saving model to checkpoints\\FSRCNN168.ckpt\n",
      "13132/13132 [==============================] - 639s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 169/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00169: saving model to checkpoints\\FSRCNN169.ckpt\n",
      "13132/13132 [==============================] - 642s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 170/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00170: saving model to checkpoints\\FSRCNN170.ckpt\n",
      "13132/13132 [==============================] - 640s 49ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 171/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00171: saving model to checkpoints\\FSRCNN171.ckpt\n",
      "13132/13132 [==============================] - 675s 51ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 172/300\n",
      "13131/13132 [============================>.] - ETA: 0s - loss: 0.0018"
     ]
    }
   ],
   "source": [
    "# config and parameters \n",
    "IS_FSRCNN_S = False    # is FSRCNN_S or FSRCNN\n",
    "RESUME = True   # Train from scratch or use previously traind weights \n",
    "n_tfrecords = 32\n",
    "batch_size = 16\n",
    "epochs = 300\n",
    "\n",
    "# prep the dataset\n",
    "train_dir = [f\"../tfrecords/div2k_train{i}.tfrecords\" for i in range(n_tfrecords)]\n",
    "valid_dir = [f\"../tfrecords/div2k_valid{i}.tfrecords\" for i in range(n_tfrecords)]\n",
    "train_dataset = tf.data.TFRecordDataset(train_dir).map(preprocess).batch(batch_size)\n",
    "valid_dataset = tf.data.TFRecordDataset(valid_dir).map(preprocess).batch(batch_size)\n",
    "\n",
    "# prep the model \n",
    "model = FSRCNN(d=32, s=5, m=1, r=4) if IS_FSRCNN_S else FSRCNN()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer, loss=loss_fn)\n",
    "\n",
    "name_model = \"FSRCNN_S\" if IS_FSRCNN_S else \"FSRCNN\"\n",
    "log_dir = f\"logs/{name_model}\"       \n",
    "checkpoint_path  = f\"checkpoints/\"+ name_model+\"{epoch:03d}.ckpt\"\n",
    "\n",
    "\n",
    "if RESUME: \n",
    "    # load pre-trained model \n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)\n",
    "\n",
    "# Training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                     patience = 3, \n",
    "                                     restore_best_weights = True),\n",
    "\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                        verbose = 1,\n",
    "                                        monitor=\"loss\",\n",
    "                                        save_freq=\"epoch\"),\n",
    "\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, update_freq=\"epoch\")\n",
    "]\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "           initial_epoch=148, \n",
    "           epochs=epochs, \n",
    "           callbacks=callbacks, \n",
    "           validation_data=valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_model(): \n",
    "    model = FSRCNN(d=32, s=5, m=1, r=4) if IS_FSRCNN_S else FSRCNN()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer, loss=loss_fn)\n",
    "\n",
    "    name_model = \"FSRCNN_S\" if IS_FSRCNN_S else \"FSRCNN\"\n",
    "    checkpoint_path  = f\"checkpoints/\"+ name_model+\"{epoch:03d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c232fb63c5daf51f391ec7aa745d18d601770bd1c72af5c1d94ffac76383052"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('deepsr': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
